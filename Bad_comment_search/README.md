# Описание задачи: 
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

# Описание данных: 
Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

# Общий итог: 
В ходе исследования была подобрана лучшая модель классичесткого ML - LogisticRegression, метрика f1 на тестовой выборке составила 0.779 c учетом калиборвки вероятностей класса 1. Ввиду огромной выборки, обучения на всех данных не представляется возможным, необходимо сокращать датафрейм. Градиентные бустинги показали неудволетворительынй результат ввиду ресурсных ограничений, т.к. данные методы очень затраты по памяти. В модели BERT можно увидеть потенциал, но данный метод аналогично ограничен по времени и памяти (в первую очереть память).
Из предобученных готовых моделей лучшей оказалась модель fasttext, метрика f1 на ней составила 0.96. В данном случае это самый лучший результат из всех исследованных моделей.